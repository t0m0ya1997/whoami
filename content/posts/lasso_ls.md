---
title: LASSO と僕は同い年：① 線形回帰
date: 2022-01-28
categories: [Research-ish, Programming]
tags: [Machine Learning, Mathematical Optimization]
image: 
math: true
draft: true
---

本記事では，LASSOへの足掛かりとして，線形回帰モデルを紹介します．
線形回帰モデルはとてもシンプルなモデルであり

### 直線から始める線形回帰モデル
まずは簡単な例で直感的な理解を深めてみましょう．
例えば，図のようなデータが与えられたとします．

中学生で学んだ$1$次関数を復習します．
入力変数を $x\in\mathbb R^1$, 出力変数を $y\in\mathbb R^1$ とします．
$1$次関数は傾き $a\in\mathbb R^1$ と切片 $b\in\mathbb R^1$ を用いて，

$$
    y = ax + b
$$

で表されます．

今，画像のようなデータが与られているとしましょう．

![image](../lasso_ls_0.png)

図の中には，$n$個の点 $(x_i, y_i)_{i=1}^n,~~x_i,y_i\in\mathbb R,$ が描写されています．
また，それぞれの点において，$x_i, y_i$ の関係は

$$
    y_i = ax_i + b + \epsilon
$$

で表されており，$a = 2, b = 1$ としています．
この $y=2x+1$ の直線を図中の赤線で示しています．
ここで，$\epsilon$ はノイズを意味し，この図の例では，平均 $0$，分散 $1$ のガウス分布 $\mathcal N(0,1)$ に従う確率変数の実現値とします．

であることを仮定するモデルを**線形回帰モデル**と呼びます．
ここで，$\epsilon\in\mathbb R^1$ は出力に加重されるノイズ，もしくは誤差です．
線形回帰モデルのパラメータは $\bm w$ ですが，$n$ 個のデータ $(x^n,y^n)$ が与えられた際に，全ての入出力関係を表現できる回帰係数となることが理想です．


### 入力変数を多次元に拡張

### 出力変数を多次元へ拡張

### 一般化線形回帰モデル


