<!DOCTYPE html>
<html lang="jp">

<head><title>
    MCMCによる混合ガウスモデル（GMM）のベイズ推論 | 
    
    TH&#39;s Blog</title>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description" content="この記事では，混合モデルのMCMCによるベイズ推論を紹介します．
    ">


<meta property="og:title" content="MCMCによる混合ガウスモデル（GMM）のベイズ推論" />
<meta property="og:description" content="この記事では，混合モデルのMCMCによるベイズ推論を紹介します．" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://t0m0ya1997.github.io/whoami/posts/mcmc_gmm/" /><meta property="og:image" content="https://t0m0ya1997.github.io/whoami/image/profile.webp"/><meta property="article:section" content="posts" />




<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://t0m0ya1997.github.io/whoami/image/profile.webp"/>

<meta name="twitter:title" content="MCMCによる混合ガウスモデル（GMM）のベイズ推論"/>
<meta name="twitter:description" content="この記事では，混合モデルのMCMCによるベイズ推論を紹介します．"/>

<meta itemprop="name" content="MCMCによる混合ガウスモデル（GMM）のベイズ推論">
<meta itemprop="description" content="この記事では，混合モデルのMCMCによるベイズ推論を紹介します．">

<meta itemprop="wordCount" content="4017"><meta itemprop="image" content="https://t0m0ya1997.github.io/whoami/image/profile.webp"/>
<meta itemprop="keywords" content="Bayesian Estimation,Mixture Model,Machine Learning,MCMC," />
<link rel="canonical" href="https://t0m0ya1997.github.io/whoami/posts/mcmc_gmm/" />

<link rel="icon" type="image/png" href="https://t0m0ya1997.github.io/whoamiimage/favicon.ico">

<link rel="stylesheet" href="/whoami/css/font-awesome.min.css">
<link rel="stylesheet" href="/whoami/css/bulma.min.css">



<script async src="https://www.googletagmanager.com/gtag/js?id=G-6379MX42G5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6379MX42G5');
</script>



<script src=/whoami/js/ramium.js></script>
<link rel="stylesheet" href=/whoami/css/ramium.css>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
              
              
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '$', right: '$', display: false},
                  {left: '\\(', right: '\\)', display: false},
                  {left: '\\[', right: '\\]', display: true}
              ],
              
              throwOnError : false
            });
        });
    </script>


</head>

<body><nav class="navbar is-dark" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href=/whoami/>
      
      <strong>TH&#39;s Blog </strong>
      
    </a>

    <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false"
      data-target="navbarBasicExample">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

  <div id="navbarBasicExample" class="navbar-menu">
    <div class="navbar-start">
      
      
      <a class="navbar-item" href="/whoami/">Home</a>
      
      
      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">This Blog</a>
        <div class="navbar-dropdown">
          
          <a class="navbar-item" href="/whoami/tags/">All Tags</a>
          
          <a class="navbar-item" href="/whoami/sections/">All Sections</a>
          
          <a class="navbar-item" href="/whoami/posts/">All Posts</a>
          
          <a class="navbar-item" href="/whoami/drafts/">書き溜め置き場</a>
          
        </div>
      </div>
      
      
      
      <a class="navbar-item" href="/whoami/author/">Author</a>
      
      
    </div>

    <div class="navbar-end">
      
      <a class="navbar-item navgithub" href="https://github.com/t0m0ya1997/whoami/" target="_blank">
        <i class="fa fa-github fa-2x"></i>
      </a>
      

      
    </div>
  </div>
</nav><div class="columns is-centered">
        <div id="page-body" class="column is-7">

<div class="content blog">
    <h1>MCMCによる混合ガウスモデル（GMM）のベイズ推論</h1>

    <div id="infobar" class="level is-mobile">
        <div class="level-left">
            
            <div class="level-item">
                <p class="subtitle info date">Jan 1, 0001
                </p>
            </div>
            

            <div class="level-item">
                <p class="subtitle info">
                    22 mins read
                </p>
            </div>
        </div>
        <div class="level-right is-hidden-touch">
            <div class="tags">
                
                <a class="tag is-dark is-rounded" href="/whoami/tags/bayesian-estimation">Bayesian Estimation</a>
                
                <a class="tag is-dark is-rounded" href="/whoami/tags/mixture-model">Mixture Model</a>
                
                <a class="tag is-dark is-rounded" href="/whoami/tags/machine-learning">Machine Learning</a>
                
                <a class="tag is-dark is-rounded" href="/whoami/tags/mcmc">MCMC</a>
                
            </div>
        </div>
    </div>

    <div class="tags is-hidden-desktop">
        
        <a class="tag is-dark is-rounded" href="/whoami/tags/bayesian-estimation">Bayesian estimation</a>
        
        <a class="tag is-dark is-rounded" href="/whoami/tags/mixture-model">Mixture model</a>
        
        <a class="tag is-dark is-rounded" href="/whoami/tags/machine-learning">Machine learning</a>
        
        <a class="tag is-dark is-rounded" href="/whoami/tags/mcmc">MC MC</a>
        
    </div>

    <div class="blog-text">
        

        <h3 id="そもそも">そもそも</h3>
<p>混合ガウスモデル（<strong>GMM</strong>：Gaussian Mixture Model）とは何でしょう．
はじめに直感的な紹介をします．</p>
<p>以下のようなデータが与えられたとしましょう．</p>
<p><img src="hoge" alt="hoge"></p>
<p>「なんか３つの塊がある」といった印象を受けますね．
これらのデータ点には，所属を表すラベルがついていません．
しかしながら，<strong>あるルール</strong>に従ってうまく分類することができれば，以下のようにできそうですよね．</p>
<p><img src="hoge" alt="hoge"></p>
<p>このように，<strong>正解となるラベルが与えられていない場合にデータの傾向や特徴を学習すること</strong>（また，それらを使って分類を行うこと）を「<mark>教師なし学習</mark>」と言います．
GMMも教師なし学習の１つで，上にあげたようにデータを分類することに使われたりします．</p>
<p>先ほども述べた<strong>あるルール</strong>というのを決めるというのが，機械学習モデルを決めることに他なりません．
今回は，GMMというルールに基づいてデータを分類すると上のような結果が得られますよ，というお話です．</p>
<p>GMMとは混合ガウスモデル（GMM：Gaussian Mixture Model），すなわち，いくつかのガウス分布の混合モデルです．
みなさんがよく知る単一のガウス分布は以下の形状じゃないでしょうか．</p>
<p><img src="hoge" alt="hoge"></p>
<p>このガウス分布に従って発生するデータというのは，ガウス分布の平均値付近に集中するはずです．
しかし，データがいくつかの混合から発生している場合，１つのガウス分布から発生しているとは考えにくそうです．
そこで，こんな感じのガウス分布を混合させたものを考えるわけです．</p>
<p><img src="hoge" alt="hoge"></p>
<p>こうすると，それぞれのガウス分布の平均値付近からデータが発生すると考えられます．
すなわち，いくつかの混合からなるデータにも対応できるようになります．</p>
<p>この例は1次元で説明しましたが，多次元空間を考えることもできます．
この記事では，2次元データに対してGMMというルールを定めてみます．</p>
<h3 id="gmm-の定式化">GMM の定式化</h3>
<p>混合ガウスモデル(Gaussian Mixture Model：GMM)の定式化を行います．
本記事では，2次元のGMMを考えます．
与えられた $n$ 個の $2$ 次元データ $x^n=(\bm x_1,\bm x_2,\cdots,\bm x_n),~\bm x_i\in\mathbb R^2,~(i=1,2,\cdots,n)$ が，以下の $K$ 個のガウス分布の混合により生成されたと仮定するのがGMMです．</p>
<p>$$
p(x^n|\pi^K,\mu^K,\Sigma^K)=\prod_{i=1}^n\left(\sum_{k=1}^K\pi_k\mathcal N(\bm x_i|\bm\mu_k,\Sigma_k^{-1})\right)
\tag{1}
$$</p>
<p>ここで，各パラメータの説明をします．
$\pi^K=(\pi_1,\pi_2,\cdots,\pi_K)$ は<strong>混合比</strong>です．
$\pi_k$ は，$k$ 番目の混合における混合比を表し，データ全体の中で $k$ 番目の混合が占める相対的な比を表します．
よって，</p>
<p>$$
\sum_{k=1}^K\pi_k = 1
\tag{2}
$$</p>
<p>が成り立ちます．</p>
<p>$\mu^K=(\bm\mu_1,\bm\mu_2,\cdots,\bm\mu_K)$ は各混合におけるガウス分布の<strong>平均</strong>を表します．
「各混合の中心」のようなものです．
また，$\Sigma^K=(\Sigma_1,\Sigma_2,\cdots,\Sigma_K)$ は各混合におけるガウス分布の<strong>分散・共分散行列</strong>を表します．
「各混合でのデータの広がり方」に相当します．</p>
<p>GMMの定義は以上なのですが，よりモデルとして扱いやすいように，<strong>潜在変数</strong>を導入します．
人によっては「<strong>ラベル変数</strong>」と呼ぶ方がわかりやすいかもしれません．
ここでの潜在変数は，ある1つのデータ点が「<strong>どの混合に属するか</strong>」を明示的に表現します．
潜在変数を $l^n = (\bm l_1,\bm l_2,\cdots,\bm l_n)$ と表します．
ここで，ある $i$ 番目のデータ点 $\bm x_i$ に対応する潜在変数 $\bm l_i$ は，one-hotなベクトル，すなわち，</p>
<p>$$
\bm l_i \in\{0,1\}^K,||\bm l_i||=1
\tag{3}
$$</p>
<p>を満たすようなベクトルとします．
この潜在変数を用いると，式(1)の生成モデルは，</p>
<p>$$
p(x^n,l^n|\pi^K,\mu^K,\Sigma^K) = \prod_{i=1}^n\prod_{k=1}^K\pi_k^{l_{i,k}}\mathcal N(\bm x_i|\bm\mu_k,\Sigma_k^{-1})^{l_{i,k}}
\tag{4}
$$</p>
<p>と書き直すことができます．
ここで，潜在変数 $l^n$ について周辺化すると式(1)となることも確認できます．</p>
<p>以上より，GMMのデータの発生過程（確率モデル）を以下のように仮定します．</p>
<style type="text/css">.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#444;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative}</style>
<div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice note"  id="データ生成の流れ" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"></use></svg></span>データ生成の流れ</p><ol>
<li>混合数 $K$ が決定する．</li>
<li>各混合における混合比 $\pi^K$，平均 $\mu^K$，分散・共分散行列 $\Sigma^K$ がそれぞれの事前分布 $p(\pi|K),p(\mu|K),p(\Sigma|K)$ より発生する．</li>
<li>混合比 $\pi^K$ に基づいて，潜在変数 $l^n$ が発生する．</li>
<li>$i$ 番目のデータ点について，式(4)に基づいて，$\bm x_i$ が発生する $(i=1,2,\cdots,n)$．</li>
</ol></div>


<p>簡単のために，本記事では<strong>各混合の分散・共分散行列は単位行列である</strong> $^1$ という制約を課します．
これは，「<strong>データは属する混合の中心から等方的に広がり生成される</strong>」ということになります．
定数値とすることで，$\Sigma^K$ は推定するパラメータから除去されます．
また，混合数 $K$ の値は $K=3$ と事前に決めておきます $^{2, 3}$ ．</p>
<p>確率モデルのパラメータの依存関係を表現するグラフィカルモデルで表すと，以下のようになります．</p>
<div class="notice warning"  id="注釈" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#warning-notice"></use></svg></span>注釈</p><ol>
<li>
<p>本記事では，分散・共分散行列は対角行列であることを仮定しましたが，これは今回紹介するLabel Switching を説明する上で，そこまで重要ではないため簡略化しました．
一般の場合にはこれらも推定する場合が多いです．</p>
</li>
<li>
<p>混合数についても，固定値として扱いました．
「適当に決めた混合数で推定して良いのか？」という疑問が湧き上がると思います．
その疑問は至極真っ当なものです．
本来は，混合数 $K$ をモデルのハイパーパラメータとして扱い，<strong>モデル選択</strong>により最適なモデル（混合数）を決定することが多いです．</p>
</li>
<li>
<p>さらなる注意点なのですが，<strong>BIC</strong>(ベイズ情報量規準)や<strong>AIC</strong>（赤池情報量規準）などを評価しモデル選択を行うと言う話を聞いたことがあるかもしれません．
これらは，パラメータのベイズ事後分布の漸近正規性が成り立つときに正しい値を示します．
一方で，この記事で扱う混合モデルはパラメータの事後分布に必ずしも漸近正規性が成り立つとは言えない<strong>特異モデル</strong>に属します．
特異モデルでは，<strong>AICやBICによるモデル選択が有効ではない</strong>こともあるので注意が必要です．
<strong>WAIC,WBIC</strong>という情報量規準は，特異モデルでも使用できる基準として提案されました．
気になる方は是非調べてみてください．</p>
</li>
</ol></div>


<h3 id="gmm-のベイズ推論">GMM のベイズ推論</h3>
<p>さて，本題に入ります．
グラフィカルモデルから，GMMの全変数の同時分布は以下のようになります．</p>
<p>$$
p(x^n, l^n, \pi^K, \mu^K) = p(x^n, l^n|\pi^K,\mu^k)p(\pi^K)p(\mu^K)
\tag{5}
$$</p>
<p>与えられるデータは $x^n$ のみです．
このデータ $x^n$ が与えられた際の各パラメータの事後分布は</p>
<p>$$
p(l^n, \pi^K, \mu^K | x^n) \propto p(x^n, l^n|\pi^K,\mu^k)p(\pi^K)p(\mu^K)
\tag{6}
$$</p>
<p>となります．
ここで，$p(x^n, l^n|\pi^K,\mu^k)$ が<strong>尤度関数</strong>，$p(\pi^K),p(\mu^K)$ はそれぞれ<strong>事前分布</strong>です．</p>
<p>事前分布を具体的に定めます．
混合比 $\pi^K$ の事前分布は，以下の<strong>ディリクレ（Dirichlet）分布</strong>を仮定します．</p>
<p>$$
p(\pi^K|\bm\alpha) = \text{Dir}(\pi^K|\bm\alpha)=\frac{1}{\text{B}(\bm\alpha)}\prod_{k=1}^K\pi_k^{\alpha_k - 1},~~~~~\bm\alpha=(\alpha_1,\alpha_2,\cdots,\alpha_K)\in\mathbb R^K
\tag{7}
$$</p>
<p>$\text{B}(\bm\alpha)$はベータ関数です．
ハイパーパラメータ $\bm\alpha$ は $\mathbb I^K$ とします．</p>
<p>また，平均 $\mu^K$ の事前分布は以下の<strong>ガウス分布</strong>を仮定します．</p>
<p>$$
p(\mu^K) = \prod_{k=1}^K\mathcal N(\bm\mu_k|0,3I) = \left(6\pi\right)^{-K}\prod_{k=1}^K\exp\left(-\frac{||\bm\mu_k||_2^2}{6}\right)
\tag{8}
$$</p>
<p>これらを用いると，注目している変数のみを抽出して，事後分布は以下のように書けます．</p>
<p>$$
p(l^n, \pi^K, \mu^K | x^n) \propto \left\{\prod_{i=1}^n\prod_{k=1}^K\pi_k^{l_{i,k}}\mathcal N(\bm x_i|\bm\mu_k,\Sigma_k^{-1})^{l_{i,k}}\right\}\left\{\prod_{k=1}^K\pi_k^{\alpha_k - 1}\right\}\left\{\prod_{k=1}^K\exp\left(-\frac{||\bm\mu_k||_2^2}{6}\right)\right\}
\tag{9}
$$</p>
<h3 id="mcmcを構成する">MCMCを構成する</h3>
<p>これから，式(9)の事後分布に従う確率変数からサンプリングを行うためのMCMC（マルコフ連鎖モンテカルロ法）のアルゴリズムを構築します．
今回は以下のように，各変数を順にサンプリングしていく<strong>Gibbs Sampling</strong> を行います．
$$
\mu^K\sim p(\mu^K|\pi^K,l^n)
\tag{10}
$$</p>
<p>$$
\pi^K\sim p(\pi^K|\mu^K,l^n)
\tag{11}
$$</p>
<p>$$
l^n\sim p(l^n|\mu^K,\pi^K)
\tag{12}
$$</p>
<h5 id="mark各混合の平均の更新則mark"><mark>各混合の平均の更新則</mark></h5>
<p>平均 $\mu^K$ の更新について考えます．
式(9)の事後分布において，平均 $\mu^K$ に依存する項のみを抽出すると</p>
<p>$$
p(\mu^K|\pi^K,l^n) \propto \left\{\prod_{i=1}^n\prod_{k=1}^K\mathcal N(\bm x_i|\bm\mu_k,I)^{l_{i,k}}\right\}\left\{\prod_{k=1}^K\exp\left(-\frac{||\bm\mu_k||_2^2}{6}\right)\right\}
\tag{13}
$$</p>
<p>となります．
ここで，$k$ 番目の混合の平均 $\bm\mu_k$ の更新を考えます．
式(13)を $\bm\mu_k$ に着目した形で変形すると，詳細は省きますが，</p>
<p>$$
\begin{aligned}
p(\mu^K|\pi^K,l^n)
&amp;\propto  \left\{\prod_{i\in k\text{-th class}}\exp\left(-\frac{||\bm x_i-\bm\mu_k||_2^2}{2}\right)\right\}\left\{\exp\left(-\frac{||\bm\mu_k||_2^2}{6}\right)\right\}\cr
%&amp;= \exp\left\{-\frac{\sum_{i\in k\text{-th class}}||\bm x_i-\bm\mu_k||_2^2 + \frac{1}{3}||\bm\mu_k||_2^2}{2}\right\}\cr
%&amp;= \exp\left\{-\frac{1}{2}\left(\sum_{i\in k\text{-th class}}\left\{\bm x_i^T\bm x_i - 2\bm x_i^T\bm\mu_k + \bm\mu_k^T\bm\mu_k\right\} + \frac{1}{3}\bm\mu_k^T\bm\mu_k\right)\right\}\cr
%&amp; \propto \exp\left\{-\frac{1}{2}\left(\sum_{i\in k\text{-th class}}\left\{-2\bm x_i^T\bm\mu_k\right\} + n_k\bm\mu_k^T\bm\mu_k + \frac{1}{3}\bm\mu_k^T\bm\mu_k\right)\right\}\cr
%&amp;= \exp\left\{-\frac{1}{2}\left(-2\bar{\bm x}_k^T\bm\mu_k + \frac{3n_k + 1}{3}\bm\mu_k^T\bm\mu_k\right)\right\}\cr
%&amp;= \exp\left\{-\frac{3n_k+1}{6}\left(-\frac{6}{3n_k + 1}\bar{\bm x}_k^T\bm\mu_k + \bm\mu_k^T\bm\mu_k\right)\right\}\cr
&amp;\propto \exp\left\{-\frac{3n_k+1}{6}\left|\left|\bm\mu_k - \frac{3}{3n_k + 1}\bar{\bm x}_k\right|\right|_2^2\right\}\cr
&amp;\propto \mathcal N\left(\bm\mu_k\Bigg|\frac{3}{3n_k + 1}\bar{\bm x}_k, \frac{3}{3n_k + 1}I\right)
\end{aligned}
\tag{14}
$$</p>
<p>となります．
ここで，$i\in k\text{-th class}$ は，$k$ 番目の混合に属するデータの添字 $i$ の集合を意味し，$\bar{\bm x}_k$ は，$k$ 番目の混合におけるデータの和を表します．
つまり，</p>
<p>$$
\bar{\bm x}_k = \sum_{i\in k\text{-th class}}\bm x_i
\tag{15}
$$</p>
<p>です．
これより，$k$ 番目の混合の平均 $\bm\mu_k$ の更新は<strong>事前分布であるガウス分布の更新</strong>となります．
よって，この更新後のガウス分布からサンプリングを行います．
この操作を $k=1,2,\cdots, K$ ついて行えば良さそうです．</p>
<div class="notice note"  id="観察" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"></use></svg></span>観察</p><p>式(14)の事後分布であるガウス分布の分散・共分散行列にかかる係数が，その混合に属するデータ数に従って小さくなることが観察できます．
このことから，データ数が多い混合ほど，平均の推定精度が上がることが予想できます．</p>
<p>また，式(14)のガウス分布の平均を見てみると，$n_k\rightarrow\infty$ であれば，$\bar{\bm x}_k$ は $k$ 番目に属するデータ点の平均となっていることがわかります．
データ数が少ないと，事前分布の影響である，分母の $+1$ が効いてきそうです．</p></div>


<h5 id="mark混合比の更新則mark"><mark>混合比の更新則</mark></h5>
<p>混合比 $\pi^K$ の更新について考えます．
式(9)の事後分布において，混合比 $\pi^K$ に依存する項のみを抽出すると</p>
<p>$$
p(\pi^K|\mu^K,l^n) \propto \left\{\prod_{i=1}^n\prod_{k=1}^K\pi_k^{l_{i,k}}\right\}\left\{\prod_{k=1}^K\pi_k^{\alpha_k - 1}\right\}
\tag{16}
$$</p>
<p>となります．
これを， $k$ 番目の混合に属するデータ点の数 $n_k$ を用いて変形すると</p>
<p>$$
p(\pi^K|\mu^K,l^n) \propto \prod_{k=1}^K\pi_k^{n_k-\alpha_k - 1} \propto \text{Dir}(\pi^K|\bm\alpha')
\tag{17}
$$
となります．
ここで，$\bm\alpha'$ は</p>
<p>$$
\bm\alpha' = (n_1 - \alpha_1 - 1, n_2 - \alpha_2 - 1, \cdots, n_K - \alpha_K - 1)
\tag{18}
$$</p>
<p>で，混合比 $\pi^K$ の更新は，<strong>事前分布であるディリクレ分布の更新</strong>となることがわかります．
よって，この更新後のディリクレ分布からのサンプリングを行います．</p>
<h5 id="mark潜在変数の更新則mark"><mark>潜在変数の更新則</mark></h5>
<p>潜在変数 $l^n$ の更新について考えます．
式(9)の事後分布において，潜在変数 $l^n$ に依存する項のみを抽出すると，</p>
<p>$$
p(l^n|\mu^K,\pi^K) \propto \left\{\prod_{i=1}^n\prod_{k=1}^K\pi_k^{l_{i,k}}\mathcal N(\bm x_i|\bm\mu_k,\Sigma_k^{-1})^{l_{i,k}}\right\}
\tag{19}
$$</p>
<p>となります．
ここでさらに，$i$ 番目の潜在変数のみを抽出すると，</p>
<p>$$
p(\bm l_i|\mu^K,\pi^K) \propto \left\{\prod_{k=1}^K\pi_k^{l_{i,k}}\mathcal N(\bm x_i|\bm\mu_k,\Sigma_k^{-1})^{l_{i,k}}\right\}
\tag{20}
$$</p>
<p>となります．
式(20)の値は，とりうる $\bm l_i$ の全てについて求めることができます．
（<mark>これは，$i$ 番目のデータの $1$ 番目の混合，$2$ 番目の混合，$\dots$，$K$ 番目の混合への所属確率を計算していることになります．</mark>）
そうすると，正規化を行うことで，$\bm l_i$ の事後確率が出来上がります．
そこからサンプリングを行います．</p>
<h3 id="数値実験">数値実験</h3>
<p>冒頭で示した2次元データを再掲します．
このデータは，混合比を</p>
<p>$$
\pi_1 = 0.2, \pi_2 = 0.3, \pi_3 = 0.5
$$
とし，各混合における平均値は</p>
<p>$$
\bm\mu_1 = (-2, -2), \bm\mu_2 = (0, 2), \bm\mu_3 = (-2, 2)
$$</p>
<p>としてデータを発生させたものです．</p>
<h3 id="まとめ">まとめ</h3>

    </div>
</div><div id="social-media-share" class="has-text-centered">
	<p><i>Sharing makes me happy :)</i></p>
	<br>
	
	<div class="share-buttons">
	    <a  href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f"
	        onclick="socialMediaPopUp(this.href, '', 500, 500); return false;"
	        title="Share on Facebook. Opens in a new window.">
	        <img src=/whoami/img/icons/45px/facebook.png>
	    </a>

	    <a  href="https://twitter.com/intent/tweet?text=MCMC%e3%81%ab%e3%82%88%e3%82%8b%e6%b7%b7%e5%90%88%e3%82%ac%e3%82%a6%e3%82%b9%e3%83%a2%e3%83%87%e3%83%ab%ef%bc%88GMM%ef%bc%89%e3%81%ae%e3%83%99%e3%82%a4%e3%82%ba%e6%8e%a8%e8%ab%96&url=https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f"
	        onclick="socialMediaPopUp(this.href, '', 500, 500); return false;"
	        title="Share on Twitter. Opens in a new window." >
	        <img src=/whoami/img/icons/45px/twitter.png>
	    </a>

		<a  href="http://www.reddit.com/submit?url=https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on Reddit. Opens in a new window." >
	        <img src=/whoami/img/icons/45px/reddit.png>
	    </a>

	    <a  href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on Pinterest. Opens in a new window." >
	        <img src=/whoami/img/icons/45px/pinterest.png>
	    </a>

	    <a  href="http://www.tumblr.com/share/link?url=https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on Tumblr. Opens in a new window." >
	        <img src=/whoami/img/icons/45px/tumblr.png>
	    </a>

		<a  href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f
			&title=MCMC%e3%81%ab%e3%82%88%e3%82%8b%e6%b7%b7%e5%90%88%e3%82%ac%e3%82%a6%e3%82%b9%e3%83%a2%e3%83%87%e3%83%ab%ef%bc%88GMM%ef%bc%89%e3%81%ae%e3%83%99%e3%82%a4%e3%82%ba%e6%8e%a8%e8%ab%96&summary=%e3%81%9d%e3%82%82%e3%81%9d%e3%82%82%20%e6%b7%b7%e5%90%88%e3%82%ac%e3%82%a6%e3%82%b9%e3%83%a2%e3%83%87%e3%83%ab%ef%bc%88GMM%ef%bc%9aGaussian%20Mixture%20Model%ef%bc%89%e3%81%a8%e3%81%af%e4%bd%95%e3%81%a7%e3%81%97%e3%82%87%e3%81%86%ef%bc%8e%20%e3%81%af%e3%81%98%e3%82%81%e3%81%ab%e7%9b%b4%e6%84%9f%e7%9a%84%e3%81%aa%e7%b4%b9%e4%bb%8b%e3%82%92%e3%81%97%e3%81%be%e3%81%99%ef%bc%8e%20%e4%bb%a5%e4%b8%8b%e3%81%ae%e3%82%88%e3%81%86%e3%81%aa%e3%83%87%e3%83%bc%e3%82%bf%e3%81%8c%e4%b8%8e%e3%81%88%e3%82%89%e3%82%8c%e3%81%9f%e3%81%a8%e3%81%97%e3%81%be%e3%81%97%e3%82%87&source=rafed123.github.io"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on LinkedIn. Opens in a new window." >
	        <img src=/whoami/img/icons/45px/linkedin.png>
	    </a>

	    <a  href="mailto:?subject=MCMC%e3%81%ab%e3%82%88%e3%82%8b%e6%b7%b7%e5%90%88%e3%82%ac%e3%82%a6%e3%82%b9%e3%83%a2%e3%83%87%e3%83%ab%ef%bc%88GMM%ef%bc%89%e3%81%ae%e3%83%99%e3%82%a4%e3%82%ba%e6%8e%a8%e8%ab%96&amp;body=Check out this site https%3a%2f%2ft0m0ya1997.github.io%2fwhoami%2fposts%2fmcmc_gmm%2f"
	        title="Share via Email. Opens in a new window." >
	        <img src=/whoami/img/icons/45px/mail.png>
	    </a>
	</div>
</div>


<br>
<div id="disqus_thread"></div>
<script type="text/javascript">
    (function () {
        
        
        if (window.location.hostname == "localhost")
            return;

        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        var disqus_shortname = 'ths-blog-1';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


        </div>
    </div>

<footer class="footer has-background-dark">
    <div class="content has-text-centered has-text-white">
        <p>
            © 2022 TH. Powered by
            <a class="has-text-light" href="https://github.com/gohugoio/hugo" target="_blank">
            Hugo</a>. Theme
            <a class="has-text-light" href="https://github.com/rafed123/ramium/" target="_blank">
                Ramium.
            </a>
        </p>
    </div>
</footer>
</body>

</html>